{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oQiZR3K04TAN"
   },
   "source": [
    "# The Simpsons Characters Classification with VGG-16/VGG-19/Xception\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ud8DxZrl4TAO"
   },
   "source": [
    "    Northwestern University\n",
    "\n",
    "    MSiA 432 Deep learning\n",
    "    \n",
    "    Spring 2020\n",
    "    \n",
    "    Team Project\n",
    "    \n",
    "    The Simpsons Characters Classification with VGG-16/VGG-19/Xception\n",
    "\n",
    "    \n",
    "    Notes:\n",
    "        - Heatmaps may appear black in the first few epochs. Wait until accuracy improves.\n",
    "        - The native image size is 224x224 for VGG, resize/crop your images to match\n",
    "        - Filter visualization is slow, change vizfilt_timeout for more speed or accuracy\n",
    "        - Be sure to rename/delete the basepath when changing model parameters, e.g. layers or random labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "a7a0P1_N4bVP",
    "outputId": "1ecee1f5-1afa-42a4-aa4c-d8a14edeae99"
   },
   "outputs": [],
   "source": [
    "# run the following code if you are using Google Colab\n",
    "\n",
    "##############\n",
    "# Google Colab\n",
    "##############\n",
    "\n",
    "# %tensorflow_version 2.x\n",
    "# import tensorflow as tf\n",
    "# device_name = tf.test.gpu_device_name()\n",
    "# if device_name != '/device:GPU:0':\n",
    "#   raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "# from google.colab import drive\n",
    "# from pathlib import Path\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "# root_dir = \"/content/gdrive/My Drive/\"\n",
    "# base_dir = root_dir + 'msia432project/'\n",
    "# path = Path(base_dir + 'vgg16')\n",
    "# dest = path\n",
    "# dest.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3U8gXHxx4TAP",
    "outputId": "b09f40ff-6aaf-4791-a8cd-8dae3ea726eb"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Show devices\n",
    "from tensorflow.python.client import device_lib\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "print([x.name for x in local_device_protos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "olTSK-2H4TAT",
    "outputId": "c7d9426e-fe65-420e-d271-dc4eb3c77088"
   },
   "outputs": [],
   "source": [
    "# Obligatory imports\n",
    "import os, time, numpy as np, imageio, random, pandas as pd, socket, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adagrad\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\" # Workaround for Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5vBynFp4TAW"
   },
   "outputs": [],
   "source": [
    "# Set project configuration\n",
    "model_name    = \"YOUR_MODEL_NAME\"\n",
    "basepath      = \"YOUR_BASE_PATH\"\n",
    "imsize        = (128, 128) # n x n square images, VGG default is 224x224. Remember to change this.\n",
    "tsize         = imsize + (3,)\n",
    "trainfolder   = \"data/train\"\n",
    "testfolder    = \"data/evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAj00xMZ4TAZ"
   },
   "outputs": [],
   "source": [
    "# Model settings    \n",
    "vggblocks     = 5        # Number of VGG blocks to create, 0-5 blocks\n",
    "xferlearning  = 3       # Enable transfer learning up to layer n (max 12, -1 = off)\n",
    "freeze_conv   = False    # Freeze convolutional layers\n",
    "fclayersize   = 128      # Size of fully connected (FC) layers\n",
    "fclayers      = 1        # Number of FC layers\n",
    "fcdropout     = 0.5      # Dropout regularization factor for FC layers\n",
    "alpha         = 0.01      # Leaky ReLU alpha\n",
    "l1_reg        = 0.0      # L1 regularization for FC\n",
    "l2_reg        = 0.0      # L2 regularization for FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJZp3HIj4TAc"
   },
   "outputs": [],
   "source": [
    "# Optimizer settings\n",
    "optimizer = Adam()   \n",
    "batch_size, nb_epoch = 32, 150       # Change for early stopping regularization\n",
    "batchnorm     = True                 # Batch normalization\n",
    "checkpoint    = True                 # Checkpoint models to continue training\n",
    "\n",
    "# Visualization settings\n",
    "hsv             = False              # Convert images to Hue/Saturation/Value to be more robust to color variations\n",
    "vizfilt_timeout = 3                  # Decrease for speed, increase for better viz. 0 = off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JI80xCn4TAh"
   },
   "outputs": [],
   "source": [
    "# Model checkpointing/stats\n",
    "# Select which model you want to use\n",
    "\n",
    "#modeltype     = 'vgg'      # Use default VGG model\n",
    "modeltype     = 'xception' # New Xception model, recommended imsize = (64, 64) or larger\n",
    "modelarch     = '%s%d-fcl%d-fcs%d-%s-%s' % (modeltype, vggblocks, fclayers, fclayersize, 'hsv' if hsv else 'rgb', socket.gethostname())\n",
    "modelid       = os.path.join(basepath, model_name, 'model.xception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_project_folder(basepath):\n",
    "    if os.path.exists(basepath): return\n",
    "    os.makedirs(basepath, exist_ok=True)\n",
    "    \n",
    "make_project_folder(os.path.join(basepath, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlKmjTLD4TAk"
   },
   "outputs": [],
   "source": [
    "# VGG net definition starts here. Change the vggblocks to set how many blocks to transfer\n",
    "def make_vgg():\n",
    "    from keras.models import Model\n",
    "    from keras.regularizers import l1_l2\n",
    "    from keras.layers import Flatten, Dense, Input, Convolution2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "    from keras.layers.advanced_activations import LeakyReLU\n",
    "    \n",
    "    img_input = Input(shape=tsize)\n",
    "    if vggblocks == 0: x = img_input \n",
    "    if vggblocks >= 1: # Block 1\n",
    "        x = LeakyReLU(alpha)(Convolution2D(64, (3, 3), padding='same', name='block1_conv1')(img_input))\n",
    "        x = LeakyReLU(alpha)(Convolution2D(64, (3, 3), padding='same', name='block1_conv2')(x))\n",
    "        x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "        if batchnorm: x = BatchNormalization()(x)\n",
    "    if vggblocks >= 2: # Block 2\n",
    "        x = LeakyReLU(alpha)(Convolution2D(128, (3, 3), padding='same', name='block2_conv1')(x))\n",
    "        x = LeakyReLU(alpha)(Convolution2D(128, (3, 3), padding='same', name='block2_conv2')(x))\n",
    "        x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "        if batchnorm: x = BatchNormalization()(x)\n",
    "    if vggblocks >= 3: # Block 3\n",
    "        x = LeakyReLU(alpha)(Convolution2D(256, (3, 3), padding='same', name='block3_conv1')(x))\n",
    "        x = LeakyReLU(alpha)(Convolution2D(256, (3, 3), padding='same', name='block3_conv2')(x))\n",
    "        x = LeakyReLU(alpha)(Convolution2D(256, (3, 3), padding='same', name='block3_conv3')(x))\n",
    "        x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "        if batchnorm: x = BatchNormalization()(x)\n",
    "    if vggblocks >= 4: # Block 4\n",
    "        x = LeakyReLU(alpha)(Convolution2D(512, (3, 3), padding='same', name='block4_conv1')(x))\n",
    "        x = LeakyReLU(alpha)(Convolution2D(512, (3, 3), padding='same', name='block4_conv2')(x))\n",
    "        x = LeakyReLU(alpha)(Convolution2D(512, (3, 3), padding='same', name='block4_conv3')(x))\n",
    "        x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "        if batchnorm: x = BatchNormalization()(x)\n",
    "    if vggblocks >= 5: # Block 5\n",
    "        x = LeakyReLU(alpha)(Convolution2D(512, (3, 3), padding='same', name='block5_conv1')(x))\n",
    "        x = LeakyReLU(alpha)(Convolution2D(512, (3, 3), padding='same', name='block5_conv2')(x))\n",
    "        x = LeakyReLU(alpha)(Convolution2D(512, (3, 3), padding='same', name='block5_conv3')(x))\n",
    "        x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "        if batchnorm: x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    for i in range(fclayers): \n",
    "        x = LeakyReLU(alpha)(Dense(fclayersize, kernel_regularizer=l1_l2(l1_reg, l2_reg))(x))\n",
    "        if fcdropout > 0:\n",
    "            x = Dropout(fcdropout)(x)\n",
    "    x = Dense(len(obj_classes), activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    inputs = img_input\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "    \n",
    "    # VGG Transfer weights\n",
    "    from keras.applications import vgg16\n",
    "    import keras.layers.convolutional\n",
    "    vgg16model = vgg16.VGG16(include_top=False)\n",
    "    modelconv = [l for l in model.layers if type(l) == keras.layers.convolutional.Conv2D]\n",
    "    vgg16conv = [l for l in vgg16model.layers if type(l) == keras.layers.convolutional.Conv2D]\n",
    "    \n",
    "    for i, l in enumerate(modelconv):\n",
    "        if i > xferlearning: continue # Transfer only first n layers\n",
    "        print('**** Transferring layer %d: %s from VGG ****' % (i, l))\n",
    "        weights = vgg16conv[i].get_weights()\n",
    "        modelconv[i].set_weights(weights)\n",
    "        if freeze_conv: l.trainable = False\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model, img_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cjlaUzX74TAs",
    "outputId": "28b52add-8aa7-4dc6-a82e-0375a9f7877c"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,                         # rescale data\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,    \n",
    "    rotation_range=0,                       # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.0,                  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.0,                 # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,                   # randomly flip images\n",
    "    vertical_flip=False)                    # randomly flip images\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        trainfolder,\n",
    "        target_size=imsize,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        testfolder,\n",
    "        target_size=imsize,\n",
    "        batch_size=-1)\n",
    "\n",
    "X_test, Y_test = test_generator.next()\n",
    "\n",
    "obj_classes = sorted(train_generator.class_indices.keys())\n",
    "class_to_idx = dict([(y, x) for (x,y) in enumerate(obj_classes)])\n",
    "img_rows, img_cols, img_channels = X_test.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPpZVYhe4TAv"
   },
   "outputs": [],
   "source": [
    "#%% Xception definition\n",
    "def make_xception():\n",
    "    import keras\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "    from keras.regularizers import l1\n",
    "    xmodel = keras.applications.Xception(include_top=False)\n",
    "    x = xmodel.output\n",
    "    #for layer in xmodel.layers: layer.trainable = False\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, kernel_regularizer=l1(1e-7))(x)\n",
    "    predictions = Dense(len(obj_classes), activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=xmodel.input, outputs=predictions)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam())\n",
    "    model.summary()\n",
    "    return model, xmodel.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wJvdXjli4TAy",
    "outputId": "86be3d1e-f4fe-4bbf-b856-9dc2743d70d7"
   },
   "outputs": [],
   "source": [
    "if modeltype == 'vgg':\n",
    "    model, img_input = make_vgg()    \n",
    "elif modeltype == 'xception':\n",
    "    model, img_input = make_xception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fb9BFFqO4TA0"
   },
   "outputs": [],
   "source": [
    "#%% Visualization code\n",
    "def viz_losses(stats): \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,6))\n",
    "    epoch = len(stats)\n",
    "    convlayers = len([l.name for l in model.layers if 'conv' in l.name])\n",
    "    blocks     = len(set([l.name.split('_')[0] for l in model.layers if 'block' in l.name]))\n",
    "    dense      = len([l.name for l in model.layers if 'dense' in l.name])\n",
    "    fcsize     = model.layers[-1].input_shape[1]\n",
    "    fig.suptitle(\"Training %s blocks=%d, conv=%d, dense=%d, fcsize=%d, epoch=%d\" % (model.name, blocks, convlayers, dense, fcsize, epoch))\n",
    "    ax1.plot(stats['Train loss'].values, label='Train loss', color='blue')\n",
    "    ax1.plot(stats['Test loss'].values, label='Test loss', color='green')\n",
    "    ax1.set_yscale('log')\n",
    "    ax2.plot(stats['Accuracy'].values, label='Test accuracies', color='red')\n",
    "    ax2.plot(stats['Train accuracy'].values, label='Train accuracies', color='blue')\n",
    "    ax2.axhline(1.0/len(obj_classes), linestyle='dashed', color='gray')\n",
    "    dataset = pd.Series(train_generator.classes)\n",
    "    chance = dataset.value_counts().max() / dataset.value_counts().sum()\n",
    "    ax2.text(0, chance, 'Chance')\n",
    "    ax2.axhline(np.max(stats['Accuracy']), linestyle='dashed', color='red')\n",
    "    ax2.text(0, np.max(stats['Accuracy']), 'Best')    \n",
    "    ax2.set_ylim([0, 1])\n",
    "    ax2.set_title('Accuracy: %0.2f%%' % (100.0*stats['Accuracy'].values[-1]))     \n",
    "    ax1.legend(), ax2.legend()\n",
    "    plt.savefig(os.path.join(basepath, model_name, 'Epoch-%s-loss-%s.png' % (str(epoch),modelarch)))\n",
    "    plt.show()    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cty_3Y8L4TA3"
   },
   "outputs": [],
   "source": [
    "#%% Explanations\n",
    "import skimage.exposure, skimage.filters\n",
    "from skimage.color import gray2rgb\n",
    "from keras import backend as K\n",
    "import math\n",
    "\n",
    "def hide_axes(ax): ax.set_xticks([]), ax.set_yticks([])\n",
    "class Heatmap:\n",
    "    def __init__(self, model, obj_classes):\n",
    "        self.obj_classes = obj_classes\n",
    "        self.nclasses    = len(obj_classes)\n",
    "        self.model       = model\n",
    "    \n",
    "    def make_masks(self, im, n=8, maskval=0.1):\n",
    "        masks = []\n",
    "        xwidth, ywidth = int(np.ceil(im.shape[0]/n)), int(np.ceil(im.shape[1]/n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                mask = np.ones(im.shape[:2])\n",
    "                mask[(i*xwidth):((i+1)*xwidth), (j*ywidth):((j+1)*ywidth)] = maskval\n",
    "                mask = skimage.filters.gaussian(mask, 1) # Change this for local mask smoothing\n",
    "                masks.append(mask)\n",
    "        return np.array(masks)\n",
    "\n",
    "    def get_slice_masks(self, im, n_segments=16, blur=0.03):\n",
    "        from skimage.segmentation import slic\n",
    "        segments = slic(im, n_segments=n_segments, sigma=5)\n",
    "        masks = []\n",
    "        # loop over the unique segment values\n",
    "        for (i, segVal) in enumerate(np.unique(segments)):\n",
    "            # construct a mask for the segment\n",
    "            mask = np.zeros(im.shape[:2], dtype=\"float32\")\n",
    "            mask[segments == segVal] = 1\n",
    "            mask = skimage.filters.gaussian(mask, im.shape[1]*blur) # Change this for local mask smoothing            \n",
    "            masks.append(mask)\n",
    "        return np.array(masks), segments\n",
    "        \n",
    "    def explain_prediction_heatmap(self, im, actual):\n",
    "        import skimage.color\n",
    "        def hsv_fn(im): return skimage.color.hsv2rgb(im) if hsv else im\n",
    "        plt.imshow(hsv_fn(im), interpolation='bilinear'), plt.xticks([]), plt.yticks([]), plt.title('Full image'), plt.show(), plt.close()\n",
    "        masks = np.concatenate([self.make_masks(im, n=i) for i in (9, 7, 5, 3, 2)])\n",
    "        #masks, segments = self.get_slice_masks(im)        \n",
    "        masknorm = masks.sum(axis=0)\n",
    "        heatmaps = np.zeros((self.nclasses,) + im.shape[:2])\n",
    "        for m in masks:\n",
    "            prediction = self.model.predict(np.expand_dims(im*gray2rgb(m), 0))\n",
    "            for c in range(self.nclasses):\n",
    "                heatmaps[c] += (prediction[0][c]*m)\n",
    "        for h in heatmaps: h = h / masknorm\n",
    "        fig, axes = plt.subplots(6, 7, figsize=(30, 30))\n",
    "        #axes[0,0].imshow(hsv(im)), axes[1,0].imshow(mark_boundaries(im, segments))     \n",
    "        axes[0,0].imshow(hsv_fn(im)), axes[3,0].imshow(im)       \n",
    "        \n",
    "        axes[0,0].set_title(actual)\n",
    "        axes[3,0].set_title('HSV' if hsv else 'RGB')        \n",
    "        hide_axes(axes[0,0]), hide_axes(axes[1,0])       \n",
    "        predictions = np.sum(heatmaps, axis=(1,2,))\n",
    "        predictions /= predictions.max()\n",
    "        for n, i in enumerate(np.argsort(predictions)[::-1][:self.nclasses]):\n",
    "            h = ((255 * heatmaps[i])/heatmaps[i].max()).astype('uint16')\n",
    "            try:\n",
    "                h = skimage.exposure.equalize_adapthist(h)\n",
    "            except IndexError: pass\n",
    "            h = skimage.filters.gaussian(h, 1) # Change this for global mask smoothing\n",
    "            \n",
    "            row_index = math.floor((n+1)/7)\n",
    "            col_index = (n+1)%7\n",
    "            axes[row_index, col_index].imshow(gray2rgb(h))\n",
    "            axes[row_index+3, col_index].imshow(gray2rgb(h) * hsv_fn(im) * (0.5 + 0.5*predictions[i])) \n",
    "            axes[row_index, col_index].set_title(self.obj_classes[i] + ': %0.1f%%' % (100*predictions[i]/predictions.sum()))\n",
    "            axes[row_index+3, col_index].set_title(self.obj_classes[i] + ': %0.1f%%' % (100*predictions[i]/predictions.sum()))\n",
    "        \n",
    "        for i in range(6):\n",
    "            for j in range(7):\n",
    "                hide_axes(axes[i, j])  \n",
    "                \n",
    "        for i in [2,5]:\n",
    "            for j in [5,6]:\n",
    "                fig.delaxes(axes[i,j])\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(os.path.join(basepath, model_name, 'heatmap-%05d.png') % np.random.randint(0, 99999))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        return heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tSU9NLwD4TA5"
   },
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "def deprocess_image(x):\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x = x*0.1 + 0.5\n",
    "    x = np.clip(x, 0, 1) * 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def viz_filter_max(layer_name, filter_index=0, max_steps=9999, timeout=3):\n",
    "    from keras.utils.generic_utils import Progbar            \n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    grads = K.gradients(loss, img_input)[0]\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "    iterate = K.function([img_input], [loss, grads])\n",
    "    step = 1e-0\n",
    "    input_img_data = np.random.random((1, img_rows, img_cols, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "    tm = time.time()\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "        if time.time() - tm > timeout:\n",
    "            plt.text(0.1, 0.1, \"Filter viz timeout: %d\" % timeout, color='red')\n",
    "            break\n",
    "    img = input_img_data[0]\n",
    "    img = deprocess_image(img)\n",
    "    fig = plt.imshow(img)    \n",
    "    hide_axes(fig.axes)\n",
    "    return layer_output\n",
    "    \n",
    "def viz_filters(model, img_input, img_rows, img_cols, nbfilters=3, timeout=60):\n",
    "    tm = time.time()\n",
    "    print(\"Visualizing filters (CTRL-C to cancel)\")\n",
    "    try:         \n",
    "        for layer_name in sorted(layer_dict.keys()):\n",
    "            if time.time() - tm > timeout:\n",
    "                print(\"Filter visualization timed out: %d. Change timeout in viz_filters().\" % timeout)\n",
    "                break\n",
    "            if not hasattr(layer_dict[layer_name], 'filters'): continue\n",
    "            nfilters = layer_dict[layer_name].filters\n",
    "            fig, ax = plt.subplots(1, nbfilters, figsize=(8, 4))\n",
    "            fig.suptitle(\"Layer %s has %d filters\" % (layer_name, nfilters))            \n",
    "            for j in range(nbfilters):\n",
    "                plt.subplot(1, nbfilters, j + 1)\n",
    "                viz_filter_max(layer_name, random.randint(0, nfilters-1), timeout=vizfilt_timeout)\n",
    "            fig.tight_layout()    \n",
    "            plt.savefig(os.path.join(basepath, model_name ,'filters-%s-%s.png' % (modelarch, layer_name))) \n",
    "            plt.show(), plt.close()\n",
    "    except KeyboardInterrupt: return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2Onhr8R4TA8"
   },
   "outputs": [],
   "source": [
    "def test_prediction(im, y):\n",
    "    pred = model.predict(np.expand_dims(im, 0))\n",
    "    cls = np.argmax(y)\n",
    "    heatmap = Heatmap(model, obj_classes)                \n",
    "    heatmap.explain_prediction_heatmap(im, obj_classes[cls])\n",
    "    \n",
    "    print(\"Actual: %s(%d)\" % (obj_classes[cls], cls))\n",
    "    for cls in list(reversed(np.argsort(pred)[0]))[:5]:\n",
    "        conf = float(pred[0, cls])/pred.sum()\n",
    "        print(\"    predicted: %010s(%d), confidence=%0.2f [%-10s]\" % (obj_classes[cls], cls, conf, \"*\" * int(10*conf)))\n",
    "    return pred\n",
    "\n",
    "def confusion_matrix(model, X, T, accpct):\n",
    "    import seaborn\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    Y_pred = model.predict(X)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    y_test = np.argmax(T, axis=1)\n",
    "    print('Confusion Matrix')\n",
    "    data = confusion_matrix(y_test, y_pred)\n",
    "    data = data / data.sum(axis=1)\n",
    "    #print('Classification Report')\n",
    "    #print(classification_report(y_test, y_pred, target_names=obj_classes))\n",
    "    seaborn.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "    seaborn.heatmap(data, annot=data*100, fmt='0.0f', cmap='Wistia', xticklabels=obj_classes, yticklabels=obj_classes)\n",
    "    plt.xlabel('Predicted'), plt.ylabel('Actual'), plt.title('Confusion matrix (ACC %0.2f%%)' % (accpct*100))\n",
    "    plt.show(), plt.close()\n",
    "\n",
    "def tsne_viz(model, X, Y, accpct, n=500):\n",
    "    import sklearn.manifold, matplotlib.cm as cm\n",
    "    predictions = model.predict(X)    \n",
    "    colors = iter(cm.rainbow(np.linspace(0, 1, len(obj_classes))))\n",
    "    X_embedded = sklearn.manifold.TSNE(n_components=2).fit_transform(predictions[:n])\n",
    "    for d in range(len(obj_classes)):\n",
    "        xx = X_embedded[Y[:n][:, d] == 1, 0]\n",
    "        yy = X_embedded[Y[:n][:, d] == 1, 1]\n",
    "        plt.scatter(xx, yy, c=[next(colors)], label=obj_classes[d])\n",
    "        t = plt.text(np.median(xx), np.median(yy), obj_classes[d], fontsize=24)\n",
    "        t.set_bbox({'facecolor': 'white', 'alpha': 0.75})\n",
    "    plt.title('T-SNE viz - Accuracy: %0.2f%%' % (accpct*100)), plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAGpzBwy4TA-"
   },
   "outputs": [],
   "source": [
    "if checkpoint and os.path.exists(modelid): \n",
    "    print(\"**** Loading existing model: %s ****\" % modelid)\n",
    "    try:\n",
    "        model.load_weights(modelid)\n",
    "    except ValueError:\n",
    "        print(\"Model restore failed. Model topology must match to restore weights. Please delete weight checkpoint model.h5.\")\n",
    "    except OSError:\n",
    "        print(\"Model checkpoint corrupted. Please delete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "SDR6549W4TBB",
    "outputId": "653f8391-3b29-42f2-dc67-d78193a53b6c"
   },
   "outputs": [],
   "source": [
    "#%% Training code\n",
    "from IPython.display import clear_output\n",
    "\n",
    "tm = time.time()\n",
    "trainstats = pd.DataFrame(columns=('Train loss', 'Test loss', 'Accuracy', 'Train accuracy'))\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "class VizTraining(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        clear_output(wait=True)\n",
    "        tacc = logs.get('val_accuracy')\n",
    "        trainstats.loc[len(trainstats)] = (logs.get('loss'), logs.get('val_loss'), tacc, logs.get('accuracy')) \n",
    "        confusion_matrix(model, X_test, Y_test, tacc)\n",
    "        tsne_viz(model, X_test, Y_test, tacc)        \n",
    "        viz_losses(trainstats)\n",
    "        t_ind = random.randint(0, len(X_test) - 1)        \n",
    "        test_prediction(X_test[t_ind], Y_test[t_ind])    \n",
    "        if vizfilt_timeout > 0 and np.random.randint(0, 3) == 0: \n",
    "            viz_filters(model, img_input, img_rows, img_cols)\n",
    "        if checkpoint: model.save(modelid, overwrite=True)\n",
    "        print(\"Total training time: %0.2f min, epoch: %d\" % ((time.time() - tm)/60.0, len(trainstats))) \n",
    "        print(\"Average time per epoch: %0.2f s\" % ((time.time() - tm)/len(trainstats)))\n",
    "\n",
    "loss = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=int(len(train_generator.filenames)/batch_size),\n",
    "    validation_data=(X_test, Y_test),\n",
    "    validation_steps=1,\n",
    "    verbose=1, epochs=nb_epoch,\n",
    "    use_multiprocessing=True,\n",
    "    workers=4,\n",
    "    callbacks=[VizTraining()]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "msia432_project_VGG16.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
