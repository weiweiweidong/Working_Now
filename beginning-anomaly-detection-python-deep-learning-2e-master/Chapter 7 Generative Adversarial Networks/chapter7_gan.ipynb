{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a3992a-2426-49d7-b111-816caa9fec43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seaborn:  0.12.2\n",
      "TensorFlow:  2.7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "print(f'Seaborn: ', sns.__version__)\n",
    "print(f'TensorFlow: ', tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02fabe08-2337-463f-9f44-ff449222abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\",\n",
    "        \"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \n",
    "        \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n",
    "        \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
    "        \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\", \n",
    "        \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "        \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"]\n",
    "\n",
    "df = pd.read_csv(\"data/kddcup.data.corrected\", sep=\",\", names=columns, index_col=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581dadbe-2a4c-4955-8fb6-6d46f6eca5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only 'http' attacks\n",
    "df = df[df[\"service\"] == \"http\"]\n",
    "df = df.drop(\"service\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534c2842-6db3-4a68-b455-106d8e2087a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    619046\n",
       "1      4045\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].apply(lambda x: 0 if x=='normal.' else 1)\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a36a85-a33b-4b1c-a34c-01d495f6cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatypes = dict(zip(df.dtypes.index, df.dtypes))\n",
    "\n",
    "encoder_map = {}\n",
    "for col, datatype in datatypes.items():\n",
    "    if datatype == 'object':\n",
    "        encoder = LabelEncoder()\n",
    "        df[col] = encoder.fit_transform(df[col])\n",
    "        encoder_map[col] = encoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "713a32b2-2618-49e7-9873-a87ffe75d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the variables with highest correlation with 'label'\n",
    "df2 = df.copy()\n",
    "label_corr = df2.corr()['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be10598-25c7-4353-a2a5-aa10112ba649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src_bytes',\n",
       " 'hot',\n",
       " 'num_compromised',\n",
       " 'count',\n",
       " 'serror_rate',\n",
       " 'srv_serror_rate',\n",
       " 'same_srv_rate',\n",
       " 'diff_srv_rate',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_same_srv_rate',\n",
       " 'dst_host_diff_srv_rate',\n",
       " 'dst_host_serror_rate',\n",
       " 'dst_host_srv_serror_rate']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out anything that has null entry or is not weakly correlated\n",
    "train_cols = label_corr[(~label_corr.isna()) & (np.abs(label_corr) > 0.2)]\n",
    "train_cols = list(train_cols[:-1].index)\n",
    "train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5304efab-cb87-45e3-9dda-ceffe0444ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing these two columns as their correlation with 'src_bytes' is high\n",
    "remove_cols = ['hot', 'num_compromised']\n",
    "for r in remove_cols:\n",
    "    train_cols.remove(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbfc00fe-3ef9-42a8-a6b7-372aedd6c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_map = {}\n",
    "for col in train_cols:\n",
    "    scaler = MinMaxScaler()\n",
    "    df2[col] = scaler.fit_transform(df2[col].values.reshape(-1, 1))\n",
    "    scaler_map[col] = scaler \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "159f878f-003e-4aaa-bdd3-69bab5f366ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = df2[df2['label'] == 0]\n",
    "anomaly_df = df2[df2['label'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b1d21e6-9f9e-4a60-a965-287878b33a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_norm = normal_df['label']\n",
    "x_train_norm, x_test_norm, y_train_norm, y_test_norm = train_test_split(normal_df[train_cols].values, labels_norm.values, test_size=0.15, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1291130-4ed1-44b3-90cc-c0e962e31ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional split of training dataset to create validation split\n",
    "x_test_anom, x_val_anom, y_test_anom, y_val_anom = train_test_split(anomaly_df[train_cols].values, anomaly_df['label'].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "850387d2-ef5b-405e-bee5-4b14e4f478ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional split of training dataset to create validation split\n",
    "x_train, x_val_norm, y_train, y_val_norm = train_test_split(x_train_norm, y_train_norm, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01e20694-6657-4a17-a139-a9c37230be7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "x_train:(473570, 11)\n",
      "y_train:(473570,)\n",
      "\n",
      "x_val:(53428, 11)\n",
      "y_val:(53428,)\n",
      "\n",
      "x_test:(96093, 11)\n",
      "y_test:(96093,)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.concatenate((x_test_norm, x_test_anom))\n",
    "y_test = np.concatenate((y_test_norm, y_test_anom))\n",
    "x_val = np.concatenate((x_val_norm, x_val_anom))\n",
    "y_val = np.concatenate((y_val_norm, y_val_anom))\n",
    "print(\"Shapes\")\n",
    "print(f\"x_train:{x_train.shape}\\ny_train:{y_train.shape}\")\n",
    "print(f\"\\nx_val:{x_val.shape}\\ny_val:{y_val.shape}\")\n",
    "print(f\"\\nx_test:{x_test.shape}\\ny_test:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23b95dd6-ecf6-4a84-b53d-d3de737e514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "seed = 10\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73b80682-406e-4be0-b8cb-2a41afd42bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input layer requires you to specify the dimensionality of the x-features (and not the number of samples)\n",
    "noise_dimension = 50\n",
    "data_dim = x_train.shape[-1]\n",
    "## GENERATOR\n",
    "g_in = Input(shape=(noise_dimension))\n",
    "g_h1 = Dense(4*data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal')(g_in)\n",
    "g_bn1 = BatchNormalization()(g_h1)\n",
    "g_h2 = Dense(4*data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal')(g_bn1)\n",
    "g_bn2 = BatchNormalization()(g_h2)\n",
    "g_h3 = Dense(4*data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal')(g_bn2)\n",
    "g_bn3 = BatchNormalization()(g_h3)\n",
    "g_h4 = Dense(data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal')(g_bn3)\n",
    "g_bn4 = BatchNormalization()(g_h4)\n",
    "g_out = Dense(data_dim, activation='relu', )(g_bn4)\n",
    "\n",
    "\n",
    "# Creating a model by specifying the input layer and output layer\n",
    "generator = Model(g_in, g_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f68dbad8-c262-42e3-8d61-7efbe60455d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DISCRIMINATOR\n",
    "d_in = Input(shape=(data_dim))\n",
    "d_h1 = Dense(4*data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal', )(d_in)\n",
    "d_bn1 = BatchNormalization()(d_h1)\n",
    "d_h2 = Dense(4*data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal', )(d_bn1)\n",
    "d_bn2 = BatchNormalization()(d_h2)\n",
    "d_h3 = Dense(2*data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal', )(d_bn2)\n",
    "d_bn3 = BatchNormalization()(d_h3)\n",
    "d_h4 = Dense(data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal', )(d_bn3)\n",
    "\n",
    "d_out = Dense(1, activation='linear',)(d_h4)\n",
    "\n",
    "# Creating a model by specifying the input layer and output layer\n",
    "discriminator = Model(d_in, d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "daaaf983-5b7a-4731-9785-1997b22ac262",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_optim = RMSprop(5e-5)\n",
    "d_optim = RMSprop(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "037f0c2c-7f64-48d6-a7df-29b8b5dbe1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train[:]).shuffle(len(x_train[:])).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e550e473-1e8f-43d3-a875-b2ec4673cbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n",
      "  115/116: g_loss -0.23272466659545898 | d_loss: 4.443209171295166 real -0.3765527606010437 fake 0.23272466659545898226\n",
      " 0.9933422103861518 0.9221260815822002 0.9564102564102565\n",
      "\n",
      "Epoch 1\n",
      "  115/116: g_loss -0.8314056396484375 | d_loss: 1.3387994766235352 real -0.4450206160545349 fake 0.831405639648437536\n",
      " 0.9973404255319149 0.927070457354759 0.9609224855861628\n",
      "\n",
      "Epoch 2\n",
      "  115/116: g_loss -1.8064360618591309 | d_loss: -0.49550795555114746 real -0.508586049079895 fake 1.806436061859130936\n",
      " 0.9986684420772304 0.927070457354759 0.9615384615384616\n",
      "\n",
      "Epoch 3\n",
      "  115/116: g_loss -3.4109129905700684 | d_loss: -1.8184123039245605 real -0.5498615503311157 fake 3.4109129905700684\n",
      " 0.9973579920739762 0.9332509270704573 0.9642401021711366\n",
      "\n",
      "Epoch 4\n",
      "  115/116: g_loss -5.768181800842285 | d_loss: -4.170583724975586 real -0.5694270133972168 fake 5.76818180084228545\n",
      " 0.9960681520314548 0.9394313967861557 0.9669211195928753\n",
      "\n",
      "Epoch 5\n",
      "  115/116: g_loss -9.104137420654297 | d_loss: -7.686542510986328 real -0.5778399109840393 fake 9.10413742065429715\n",
      " 0.9961340206185567 0.9555006180469716 0.9753943217665615\n",
      "\n",
      "Epoch 6\n",
      "  115/116: g_loss -13.829886436462402 | d_loss: -12.809880256652832 real -0.5801756381988525 fake 13.829886436462402\n",
      " 0.9949558638083228 0.9752781211372065 0.9850187265917604\n",
      "\n",
      "Epoch 7\n",
      "  115/116: g_loss -20.321208953857422 | d_loss: -19.457338333129883 real -0.5874105095863342 fake 20.321208953857422\n",
      " 0.9912060301507538 0.9752781211372065 0.983177570093458\n",
      "\n",
      "Epoch 8\n",
      "  115/116: g_loss -28.798673629760742 | d_loss: -27.889427185058594 real -0.5943936705589294 fake 28.798673629760742\n",
      " 0.9912060301507538 0.9752781211372065 0.983177570093458\n",
      "\n",
      "Epoch 9\n",
      "  115/116: g_loss -40.05650329589844 | d_loss: -39.10804748535156 real -0.6086999773979187 fake 40.05650329589844065\n",
      " 0.9899623588456713 0.9752781211372065 0.9825653798256538\n"
     ]
    }
   ],
   "source": [
    "def gradient_penalty(critic, real_data, generated_data):\n",
    "    alpha = tf.random.uniform([real_data.shape[0], 1], 0., 1.)\n",
    "    interpolated_data = alpha * tf.cast(real_data, 'float32') + (1. - alpha) * generated_data\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated_data)\n",
    "        critic_interpolated = critic(interpolated_data)\n",
    "        \n",
    "    gradients = tape.gradient(critic_interpolated, [interpolated_data])[0]\n",
    "    gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1]))\n",
    "    gradient_penalty = tf.reduce_mean((gradients_norm - 1.)**2)\n",
    "    \n",
    "    return gradient_penalty\n",
    "\n",
    "epochs = 10\n",
    "lambda_gp = 10\n",
    "\n",
    "g_loss = 0\n",
    "d_loss = 0\n",
    "d_loss_real = 0\n",
    "d_loss_fake = 0\n",
    "for e in range(epochs):\n",
    "    print(f'\\nEpoch {e}')\n",
    "    for i, batch_x in enumerate(train_dataset):\n",
    "        print(f'\\r  {i}/{len(train_dataset)}: g_loss {g_loss} | d_loss: {d_loss} real {d_loss_real} fake {d_loss_fake}'.ljust(100, ' '), end='')\n",
    "\n",
    "        random_noise = tf.random.normal([len(batch_x), noise_dimension])\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            g_output = generator(random_noise)\n",
    "\n",
    "            real_outputs = discriminator(batch_x)\n",
    "            fake_outputs = discriminator(g_output)\n",
    "\n",
    "            g_loss = -1*tf.keras.backend.mean(tf.ones_like(fake_outputs) * fake_outputs)\n",
    "\n",
    "            d_loss_real = tf.keras.backend.mean(tf.ones_like(real_outputs) * real_outputs)\n",
    "            d_loss_fake = tf.keras.backend.mean(tf.ones_like(fake_outputs) * fake_outputs)\n",
    "\n",
    "            # # d_loss = d_loss_real - d_loss_fake \n",
    "            gp = gradient_penalty(discriminator, batch_x, g_output)\n",
    "            \n",
    "            # Combine losses\n",
    "            d_loss = d_loss_real - d_loss_fake + lambda_gp * gp\n",
    "            \n",
    "        d_grads = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "        d_optim.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "\n",
    "        g_grads = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "        g_optim.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
    "    preds = discriminator.predict(x_val)\n",
    "    preds = np.where(preds.reshape(-1) < 0, 0, 1)\n",
    "    print('\\n', precision_score(y_val, preds), recall_score(y_val, preds), f1_score(y_val, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f763a6ab-6b11-4db7-81e8-8998c56476e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32eba211-8615-44ea-b00b-8e32e14f5e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      " seed:  1 precision:  0.17236084452975048 recall:  0.5550061804697157 f1:  0.2630345635618044\n",
      "10\n",
      " seed:  10 precision:  0.9920212765957447 recall:  0.9221260815822002 f1:  0.9557975656630365\n",
      "99"
     ]
    }
   ],
   "source": [
    "# Seed search if needed. Keep the batch_size the same as when you'll be training\n",
    "results = {}\n",
    "best_score = 0\n",
    "best_seed = None \n",
    "# Can set a high batch size to make seed search go faster. Set to what your GPU can handle\n",
    "batch_size = 4096\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train[:50000]).shuffle(len(x_train[:50000])).batch(batch_size)\n",
    "for seed in range(100):\n",
    "    print(f'\\r{seed}', end='')\n",
    "    # seed = 10\n",
    "    tf.random.set_seed(seed)\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    noise_dimension = 50\n",
    "    data_dim = x_train.shape[-1]\n",
    "    ## GENERATOR\n",
    "    g_in = Input(shape=(noise_dimension))\n",
    "    g_h1 = Dense(4*data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal')(g_in)\n",
    "    g_bn1 = BatchNormalization()(g_h1)\n",
    "    g_h2 = Dense(4*data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal')(g_bn1)\n",
    "    g_bn2 = BatchNormalization()(g_h2)\n",
    "    g_h3 = Dense(4*data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal')(g_bn2)\n",
    "    g_bn3 = BatchNormalization()(g_h3)\n",
    "    g_h4 = Dense(data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal')(g_bn3)\n",
    "    g_bn4 = BatchNormalization()(g_h4)\n",
    "    g_out = Dense(data_dim, activation='relu', )(g_bn4)\n",
    "    \n",
    "    # Creating a model by specifying the input layer and output layer\n",
    "    generator = Model(g_in, g_out)\n",
    "    \n",
    "    ## DISCRIMINATOR\n",
    "    d_in = Input(shape=(data_dim))\n",
    "    d_h1 = Dense(4*data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal', )(d_in)\n",
    "    d_bn1 = BatchNormalization()(d_h1)\n",
    "    d_h2 = Dense(4*data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal', )(d_bn1)\n",
    "    d_bn2 = BatchNormalization()(d_h2)\n",
    "    d_h3 = Dense(2*data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal', )(d_bn2)\n",
    "    d_bn3 = BatchNormalization()(d_h3)\n",
    "    d_h4 = Dense(data_dim, activation=LeakyReLU(alpha=0.01), kernel_initializer = 'he_normal', )(d_bn3)\n",
    "    \n",
    "    d_out = Dense(1, activation='linear',)(d_h4)\n",
    "    \n",
    "    # Creating a model by specifying the input layer and output layer\n",
    "    discriminator = Model(d_in, d_out)\n",
    "    \n",
    "    g_optim = RMSprop(5e-5)\n",
    "    d_optim = RMSprop(1e-5)\n",
    "    \n",
    "    batch_size = 4096\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(x_train[:50000]).shuffle(len(x_train[:50000])).batch(batch_size)\n",
    "    # Add checkpointing and load the best one in relation to the validation set\n",
    "    \n",
    "    def gradient_penalty(critic, real_data, generated_data):\n",
    "        alpha = tf.random.uniform([real_data.shape[0], 1], 0., 1.)\n",
    "        interpolated_data = alpha * tf.cast(real_data, 'float32') + (1. - alpha) * generated_data\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(interpolated_data)\n",
    "            critic_interpolated = critic(interpolated_data)\n",
    "            \n",
    "        gradients = tape.gradient(critic_interpolated, [interpolated_data])[0]\n",
    "        gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1]))\n",
    "        gradient_penalty = tf.reduce_mean((gradients_norm - 1.)**2)\n",
    "        \n",
    "        return gradient_penalty\n",
    "        \n",
    "    epochs = 1\n",
    "    lambda_gp = 10\n",
    "    \n",
    "    g_loss = 0\n",
    "    d_loss = 0\n",
    "    d_loss_real = 0\n",
    "    d_loss_fake = 0\n",
    "    loss_fn = BinaryCrossentropy()\n",
    "    for e in range(epochs):\n",
    "        for i, batch_x in enumerate(train_dataset):\n",
    "            # print(f'\\r  {i}/{len(train_dataset)}: g_loss {g_loss} | d_loss: {d_loss} real {d_loss_real} fake {d_loss_fake}'.ljust(100, ' '), end='')\n",
    "    \n",
    "            random_noise = tf.random.normal([len(batch_x), noise_dimension])\n",
    "    \n",
    "            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                g_output = generator(random_noise)\n",
    "    \n",
    "                real_outputs = discriminator(batch_x)\n",
    "                fake_outputs = discriminator(g_output)\n",
    "    \n",
    "                g_loss = -1*tf.keras.backend.mean(tf.ones_like(fake_outputs) * fake_outputs)\n",
    "    \n",
    "                d_loss_real = tf.keras.backend.mean(tf.ones_like(real_outputs) * real_outputs)\n",
    "                d_loss_fake = tf.keras.backend.mean(tf.ones_like(fake_outputs) * fake_outputs)\n",
    "    \n",
    "                # # d_loss = d_loss_real - d_loss_fake \n",
    "                gp = gradient_penalty(discriminator, batch_x, g_output)\n",
    "                \n",
    "                # Combine losses\n",
    "                d_loss = d_loss_real - d_loss_fake + lambda_gp * gp\n",
    "                \n",
    "            d_grads = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "            d_optim.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "    \n",
    "          \n",
    "            g_grads = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "            g_optim.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
    "        preds = discriminator.predict(x_val)\n",
    "        preds = np.where(preds.reshape(-1) < 0, 0, 1)\n",
    "\n",
    "        f1 = f1_score(y_val, preds)\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best_seed = seed \n",
    "            print('\\n', 'seed: ', seed, \n",
    "                  'precision: ', precision_score(y_val, preds), \n",
    "                  'recall: ', recall_score(y_val, preds), \n",
    "                  'f1: ', f1_score(y_val, preds))\n",
    "        results[seed] = f1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76b72af3-a7c7-4e31-aaa1-ffeaac879ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best seed: 10 with F1: 0.9557975656630365\n"
     ]
    }
   ],
   "source": [
    "print(f'Best seed: {best_seed} with F1: {results[best_seed]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbcb3968-a2a9-4492-abc8-78e35232721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = discriminator.predict(x_test)\n",
    "y_pred = np.where(preds.reshape(-1) < 0, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44738ce9-bb93-477b-83dc-1600099dfb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.995598868280415\n",
      "Recall: 0.9786773794808405\n",
      "F1-Measure: 0.9870656069814555\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Measure: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f1ea91d-f8dd-45ea-8bf2-fc2e4d51fbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    92912\n",
       "1     3181\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af6894e7-7286-44ce-9776-9e3d6e403217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    92857\n",
       "1     3236\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03107605-3525-48bd-bf24-6f5433a05b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'True Label')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "ax = sns.heatmap(cm, annot=True, fmt='0.0f')\n",
    "ax.invert_yaxis()\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead8d8a1-0130-4f18-807e-527a370ad945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
